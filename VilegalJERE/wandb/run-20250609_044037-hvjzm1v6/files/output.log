Starting Pre-training ViLegalJERE with 47.7M parameters...
Training data size: 9, Val data size: 1
Batch size: 1, Gradient accumulation: 1
Effective batch size: 1
Mode: Pre-training, Learning rate: 0.0001, Max iters: 2
First batch shapes - Input: torch.Size([1, 512]), Decoder: torch.Size([1, 256]), Labels: torch.Size([1, 256])
iter 0: loss 9.0624, time 2549.83ms, mfu -100.00%, tps (M) 0.00, tokens trained 768.00B
step 1: train loss 9.0624, val loss nan
Saving checkpoint to /kaggle/working/out_vilegal_t5small
iter 1: loss 9.1187, time 7410.23ms, mfu -100.00%, tps (M) 0.00, tokens trained 1536.00B
step 2: train loss 9.0533, val loss nan
Saving checkpoint to /kaggle/working/out_vilegal_t5small
iter 2: loss nan, time 3343.35ms, mfu -100.00%, tps (M) 0.00, tokens trained 2304.00B
